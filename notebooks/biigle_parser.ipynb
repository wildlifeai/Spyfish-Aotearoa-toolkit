{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28574ac",
   "metadata": {},
   "source": [
    "# Biigle parser & frames extractor\n",
    "\n",
    "This notebook is used to explore parsing the annotations from the Biigle reports & extract frames from the videos.\n",
    "\n",
    "Check the streamlit page for a user friendly BIIGLE report parser.\n",
    "https://spyfish-aotearoa.streamlit.app/Export_Biigle_Annotations\n",
    "\n",
    "\n",
    "It allows you to export the reports, find MaxN, calculate sizes...\n",
    "The notebook walks you through the process. Fill in the values in the next two cells, and run the remaining cells.\n",
    "\n",
    "\n",
    "If there are any issues, or if it breaks please write an email to Kalindi, or open an issue on: \n",
    "https://github.com/wildlifeai/Spyfish-Aotearoa-toolkit/issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebcfe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEV\n",
    "# Uncomment, if you want to include local coding changes continuously.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2889cf",
   "metadata": {},
   "source": [
    "# Biigle Info \n",
    "\n",
    "If you have your BIIGLE credentials set up as .nv variables, you can leave them here None.\n",
    "\n",
    "Fill in the project & volume info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Biigle account\n",
    "BIIGLE_API_EMAIL = None\n",
    "# BIIGLE_API_EMAIL=\"kiwia@wildlife.ai\"\n",
    "\n",
    "# A token is a special password like number used for the Biigle API. \n",
    "# Find yours here: https://biigle.de/settings/tokens Keep this secret.\n",
    "BIIGLE_API_TOKEN = None\n",
    "# BIIGLE_API_TOKEN = \"Mag1CN0\"\n",
    "\n",
    "\n",
    "# The ID of the video volume you want to export annotations from.\n",
    "# You can find it on the url on biigle when you are on the page with all the clips:\n",
    "# For example: https://biigle.de/volumes/25173, 25173 is the volume id.\n",
    "# VOLUME_ID = \"25173\" # no sizes (yet.)\n",
    "# VOLUME_ID = \"25516\" # has sizes\n",
    "VOLUME_ID = \"26577\" \n",
    "PROJECT_ID = \"3711\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172be9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and installing the necessary libraries\n",
    "try:\n",
    "    from sftk.utils import ping\n",
    "except ImportError:\n",
    "    print(\"Downloading the Spyfish Aotearoa toolkit...\")\n",
    "    !pip install --upgrade --no-deps -q git+https://github.com/wildlifeai/Spyfish-Aotearoa-toolkit.git\n",
    "\n",
    "\n",
    "\n",
    "from sftk.biigle_parser import BiigleParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e58daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "biigle_parser = BiigleParser(email=BIIGLE_API_EMAIL, token=BIIGLE_API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_annotations = biigle_parser.process_video_annotations(VOLUME_ID, resource=\"volumes\")\n",
    "# Max counts every 30 seconds\n",
    "max_n_30s_df = processed_annotations[\"max_n_30s_df\"]\n",
    "# Max count of whole video (used to determine where in the videos to annotate for size)\n",
    "max_n_df = processed_annotations[\"max_n_df\"]\n",
    "# Potentially empty, if it was the video was not annotated for size.\n",
    "sizes_df = processed_annotations[\"sizes_df\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d2b5f",
   "metadata": {},
   "source": [
    "## Review the parsed dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9907ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_30s_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c5a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_n_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c35340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sizes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0015c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the processed annotations into CVS files\n",
    "\n",
    "max_n_30s_df.to_csv(f\"{VOLUME_ID}_max_n_30s_df.csv\", index=False)\n",
    "max_n_df.to_csv(f\"{VOLUME_ID}_max_n_df.csv\", index=False)\n",
    "sizes_df.to_csv(f\"{VOLUME_ID}_sizes_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff6148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export for general annotations file\n",
    "# # Not needed here, just added as a fyi\n",
    "final_annotations_output_df = biigle_parser.format_count_annotations_output(max_n_df, interval_annotation_s=30)\n",
    "final_annotations_output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251ae91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da8e1609",
   "metadata": {},
   "source": [
    "## (WIP)Export annotated frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rows:\", len(max_n_30s_df))\n",
    "print(\"columns:\", list(max_n_30s_df.columns))\n",
    "# display(max_n_30s_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ab743",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sftk.wip.biigle_frames_extract import save_grabs_from_df\n",
    "# you need to download the videos?\n",
    "save_grabs_from_df(max_n_30s_df, \"../data/biigle_files\", \"frames_out\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bdf100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, sys\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"ffmpeg:\", shutil.which(\"ffmpeg\"))\n",
    "print(\"ffprobe:\", shutil.which(\"ffprobe\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb743f1",
   "metadata": {},
   "source": [
    "## Extract frames from videos with annotations\n",
    "TODO extract this box saving code into the sftk module after testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eb9972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python pandas numpy  # if you don't already have them\n",
    "\n",
    "import ast, json, math, re\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Optional\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- helpers ---------------------------------------------------------------\n",
    "\n",
    "def _tstamp_ms(t: float) -> str:\n",
    "    \"\"\"Format seconds -> HHMMSSmmm (matches your saved frame filenames).\"\"\"\n",
    "    ms = int(round((t - math.floor(t)) * 1000))\n",
    "    tot = int(math.floor(t))\n",
    "    return f\"{tot//3600:02d}{(tot//60)%60:02d}{tot%60:02d}{ms:03d}\"\n",
    "\n",
    "_clip_pat = re.compile(r\"_clip_(\\d+)_([0-9]+)\\.\", re.IGNORECASE)\n",
    "def _is_clip(name: str) -> bool:\n",
    "    return _clip_pat.search(name) is not None\n",
    "\n",
    "def _parse_points(points_str: str) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    BIIGLE 'points' may look like:\n",
    "      \"[[x1,y1,x2,y2,x3,y3,x4,y4]]\"  OR  \"[[[x1,y1],[x2,y2],[x3,y3],[x4,y4]]]\"\n",
    "    Returns Nx2 float array.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = ast.literal_eval(points_str)\n",
    "    except Exception:\n",
    "        return None\n",
    "    if isinstance(data, list) and data:\n",
    "        inner = data[0]\n",
    "        if isinstance(inner, list) and all(isinstance(v, (int, float)) for v in inner):\n",
    "            return np.array(inner, dtype=float).reshape(-1, 2)\n",
    "        if isinstance(inner, list) and all(isinstance(v, list) and len(v) == 2 for v in inner):\n",
    "            return np.array(inner, dtype=float)\n",
    "    return None\n",
    "\n",
    "def _scale_pts_if_needed(pts: np.ndarray, img_w: int, img_h: int, attrs_json: str | None) -> np.ndarray:\n",
    "    \"\"\"If attributes has original width/height, scale polygon to actual image size.\"\"\"\n",
    "    if not attrs_json:\n",
    "        return pts\n",
    "    try:\n",
    "        attrs = json.loads(attrs_json)\n",
    "        w0, h0 = float(attrs.get(\"width\", 0)), float(attrs.get(\"height\", 0))\n",
    "        if w0 > 0 and h0 > 0:\n",
    "            return pts * np.array([img_w / w0, img_h / h0], dtype=float)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return pts\n",
    "\n",
    "def _label_color_bgr(label: str) -> tuple[int,int,int]:\n",
    "    \"\"\"Deterministic pretty-ish color per label (BGR).\"\"\"\n",
    "    h = abs(hash(label)) if label else 0\n",
    "    return (50 + (h        % 206),\n",
    "            50 + (h // 256 % 206),\n",
    "            50 + (h // 65536 % 206))\n",
    "\n",
    "def _find_frame(frames_dir: Path, video_filename: str, t_candidates: Iterable[float]) -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Find an extracted frame matching <stem>__tHHMMSSmmm__*.jpg|png...\n",
    "    Tries multiple time candidates (clip time, then original-time fallback).\n",
    "    \"\"\"\n",
    "    stem = Path(video_filename).stem\n",
    "    for t in t_candidates:\n",
    "        tag = _tstamp_ms(float(t))\n",
    "        for ext in (\"jpg\",\"png\",\"jpeg\",\"webp\",\"bmp\"):\n",
    "            hits = list(frames_dir.glob(f\"{stem}__t{tag}__*.{ext}\"))\n",
    "            if hits:\n",
    "                # pick newest if multiple\n",
    "                return sorted(hits, key=lambda p: p.stat().st_mtime, reverse=True)[0]\n",
    "    return None\n",
    "\n",
    "# --- main: overlay polygons onto existing frames ---------------------------\n",
    "\n",
    "def overlay_boxes_on_frames(\n",
    "    df: pd.DataFrame,\n",
    "    frames_dir: str | Path,\n",
    "    out_dir: str | Path,\n",
    "    *,\n",
    "    start_seconds_col: str = \"start_seconds\",\n",
    "    line_thickness: int = 3,\n",
    "    font_scale: float = 0.5,\n",
    "    fill_alpha: float = 0.25,      # 0..1; set to 0 to disable fill\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Draw all df['points'] polygons onto the already-extracted images in frames_dir,\n",
    "    writing <original>__boxed.jpg into out_dir. Returns {'drawn':N, 'skipped':M}.\n",
    "    Required df columns: video_filename, points, frames. Optional: label_name, attributes, start_seconds.\n",
    "    \"\"\"\n",
    "    need = {\"video_filename\",\"points\",\"frames\"}\n",
    "    missing = need - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"DataFrame is missing required columns: {sorted(missing)}\")\n",
    "\n",
    "    frames_dir = Path(frames_dir).resolve()\n",
    "    out_dir = Path(out_dir).resolve(); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # group all annotations by their target frame path so we load/write each image once\n",
    "    groups: dict[Path, list[dict]] = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        vid = str(row[\"video_filename\"])\n",
    "        points_str = str(row[\"points\"])\n",
    "        label = str(row.get(\"label_name\") or \"\")\n",
    "        attrs = str(row.get(\"attributes\") or \"\")\n",
    "\n",
    "        # parse time(s): BIIGLE gives frames like \"[16.02563]\"\n",
    "        try:\n",
    "            frames_val = row[\"frames\"]\n",
    "            if isinstance(frames_val, str):\n",
    "                frames_val = ast.literal_eval(frames_val)\n",
    "            if isinstance(frames_val, list) and frames_val:\n",
    "                t0 = float(frames_val[0])\n",
    "            else:\n",
    "                t0 = float(frames_val)\n",
    "        except (ValueError, SyntaxError, TypeError, IndexError):\n",
    "            continue\n",
    "\n",
    "        # figure out which timestamp our saved frame used\n",
    "        t_candidates = []\n",
    "        if _is_clip(vid):\n",
    "            t_candidates.append(t0)  # time within clip (how we saved frames in the fast/fixed code)\n",
    "        if start_seconds_col in df.columns:\n",
    "            try:\n",
    "                t_candidates.append(float(row[start_seconds_col]) + t0)  # fallback to original time naming\n",
    "            except Exception:\n",
    "                pass\n",
    "        if not _is_clip(vid):  # non-clip files\n",
    "            t_candidates.append(t0)\n",
    "\n",
    "        img_path = _find_frame(frames_dir, vid, t_candidates)\n",
    "        if not img_path:\n",
    "            continue\n",
    "\n",
    "        pts = _parse_points(points_str)\n",
    "        if pts is None or pts.size == 0:\n",
    "            continue\n",
    "\n",
    "        groups.setdefault(img_path, []).append({\"pts\": pts, \"label\": label, \"attrs\": attrs})\n",
    "\n",
    "    drawn = skipped = 0\n",
    "    for img_path, items in groups.items():\n",
    "        img = cv2.imread(str(img_path), cv2.IMREAD_COLOR)\n",
    "        if img is None:\n",
    "            skipped += 1\n",
    "            continue\n",
    "        h, w = img.shape[:2]\n",
    "        canvas = img.copy()\n",
    "\n",
    "        for it in items:\n",
    "            pts = _scale_pts_if_needed(it[\"pts\"], w, h, it[\"attrs\"])\n",
    "            pts_i = pts.astype(int).reshape(-1,1,2)\n",
    "            color = _label_color_bgr(it[\"label\"])\n",
    "\n",
    "            if fill_alpha and 0 < fill_alpha <= 1:\n",
    "                overlay = canvas.copy()\n",
    "                cv2.fillPoly(overlay, [pts_i], color)\n",
    "                cv2.addWeighted(overlay, fill_alpha, canvas, 1 - fill_alpha, 0, canvas)\n",
    "\n",
    "            cv2.polylines(canvas, [pts_i], isClosed=True, color=color, thickness=line_thickness)\n",
    "\n",
    "            if it[\"label\"]:\n",
    "                x, y = int(pts[0,0]), int(pts[0,1])\n",
    "                cv2.putText(canvas, it[\"label\"], (x, y-5),\n",
    "                            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            fontScale=font_scale, color=color, thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "        out_path = out_dir / f\"{img_path.stem}__boxed{img_path.suffix}\"\n",
    "        cv2.imwrite(str(out_path), canvas)\n",
    "        drawn += 1\n",
    "\n",
    "    return {\"drawn\": drawn, \"skipped\": skipped}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b777044",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dir = \"../data/frames_out\"\n",
    "out_dir    = \"../data/frames_out_annotated\"\n",
    "\n",
    "df = pd.read_csv(\"../data/biigle_files/26577-kok-20240219-buv-kok-060-01.csv\")\n",
    "\n",
    "summary = overlay_boxes_on_frames(df, frames_dir, out_dir)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e55dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sftk.biigle_handler import BiigleHandler\n",
    "\n",
    "bh = BiigleHandler()\n",
    "exported_annotations = bh.read_csvs_from_zip_bytes(zip_bytes)\n",
    "exported_annotations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for key in exported_annotations.keys():\n",
    "    print(len(exported_annotations[key]))\n",
    "    a+=len(exported_annotations[key])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(exported_annotations)\n",
    "a = bh.concat_csv_dict(exported_annotations)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d6f38",
   "metadata": {},
   "source": [
    "## Annotations per project level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe1c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_raw_annotations = biigle_parser.process_video_annotations(PROJECT_ID, resource=\"projects\", export_raw=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16172198",
   "metadata": {},
   "source": [
    "## Label per project level\n",
    "\n",
    "videos are Done/Nothing here etcetc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_raw_labels = biigle_parser.process_video_annotations(PROJECT_ID, resource=\"projects\", export_raw=True, type_id=10)\n",
    "\n",
    "#    \"id\" => 10,\n",
    "#    \"name\" => \"VideoLabels\\Csv\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df60cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_raw_labels[\"raw_annotations_df\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f306104",
   "metadata": {},
   "outputs": [],
   "source": [
    "erl = exported_raw_labels[\"raw_annotations_df\"]\n",
    "# erl[erl[\"label_name\"] == [\"Done\"]]\n",
    "# erl[(erl[\"label_name\"] == \"Done\") | (erl[\"label_name\"] == \"Nothing here\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9ddeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "erl[\"label_name\"].unique()\n",
    "\n",
    "# Process = Can't annotate/ random / Interesitng sighting / to review\n",
    "# - weekly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb00da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_erl = erl[(erl[\"label_name\"] == \"Done\") | (erl[\"label_name\"] == \"Nothing here\")].copy()\n",
    "not_done_erl = erl[(erl[\"label_name\"] == \"In progress\") | (erl[\"label_name\"] == \"To review\")].copy()\n",
    "\n",
    "\n",
    "not_done_erl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_erl[\"base_video\"] = done_erl[\"filename\"].str.extract(r\"^(.*?\\.mp4)\")\n",
    "video_counts = done_erl[\"base_video\"].value_counts()\n",
    "\n",
    "done_erl[\"count_for_video\"] = done_erl[\"base_video\"].map(video_counts)\n",
    "\n",
    "done_erl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bad774",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_done_erl\n",
    "\n",
    "not_done_erl[\"base_video\"] = not_done_erl[\"filename\"].str.extract(r\"^(.*?\\.mp4)\")\n",
    "video_counts = not_done_erl[\"base_video\"].value_counts()\n",
    "\n",
    "not_done_erl[\"count_for_video\"] = not_done_erl[\"base_video\"].map(video_counts)\n",
    "\n",
    "not_done_erl[\"count_for_video\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd837dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_erl[\"count_for_video\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e0c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_raw_annotations.keys(), exported_raw_labels.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "era = exported_raw_annotations[\"raw_annotations_df\"]\n",
    "era[era[\"label_name\"] == \"Done\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da8c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_processed_project_annotations = biigle_parser.process_video_annotations(PROJECT_ID, resource=\"projects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6516b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(exported_processed_project_annotations)\n",
    "exported_processed_project_annotations.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_processed_project_annotations[\"max_n_df\"][exported_processed_project_annotations[\"max_n_df\"][\"DropID\"] == \"TON_20211026_BUV_TON_016_01\"]\n",
    "\n",
    "exported_processed_project_annotations[\"max_n_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9977b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_processed_project_annotations[\"max_n_30s_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d92b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(exported_processed_project_annotations[\"max_n_30s_df\"][\"video_filename\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3fe748",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(exported_processed_project_annotations[\"max_n_df\"][\"video_filename\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608fcabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If all SurveyIDs had all 60 videos\n",
    "27*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c733aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_annotations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bfbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_annotations[\"raw_annotations_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4c30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyfish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
