{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine annotations into one csv file\n",
    "\n",
    "This notebooks is part of the Spyfish Aotearoa data cleaning efforts and is used to concatenate files containing extracted expert annotations, which is then uploaded to the S3 bucket.\n",
    "\n",
    "In the second part of the notebook, there are some visual checks to see if something is suspicious with the annotations. These output should be ready for upload, so there shouldn't be any irregularities and if there are, it means that the previous notebook (legacy_annotations_extract) needs to be updated and the export file re-run - or potentially done by hand, but with a TODO in the above notebook.\n",
    "\n",
    "TODO: Some of these checks could be repurposed for the automatic tests of the annotations being saved in the S3 buckets in the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last changed 2025.05.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from sftk.common import S3_SHAREPOINT_SURVEY_CSV\n",
    "from sftk.utils import filter_file_paths_by_extension, read_file_to_df\n",
    "from sftk.s3_handler import S3Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_folder = \"/path/to/data/Video analysis/export\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(annotations_folder)\n",
    "tabular_files = filter_file_paths_by_extension(all_files, [\"csv\"])\n",
    "tabular_files = [os.path.join(annotations_folder, file_name) for file_name in tabular_files if \"~\" not in file_name] \n",
    "tabular_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the files into one dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_annotations(all_tab_files):\n",
    "    dfs = []\n",
    "    for f in all_tab_files:\n",
    "        try: \n",
    "            dfs.append(read_file_to_df(f))\n",
    "        except Exception as e:\n",
    "            print(f\"{f} not read, {e}\")\n",
    "    combined_df = pd.concat(dfs, axis=0)\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combine_annotations(tabular_files)\n",
    "print(combined_df.shape)\n",
    "print(combined_df.columns)\n",
    "combined_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add confidence agreement NA because of expert annotations\n",
    "combined_df[\"ConfidenceAgreement\"] = \"NA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check validity of various columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review null deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if there are any problems\n",
    "combined_df[combined_df[\"ScientificName\"].isna()]\n",
    "combined_df[combined_df[\"MaxInterval\"].isna()]\n",
    "combined_df[combined_df[\"TimeOfMax\"].isna()] # This one most often shows some irregularities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.fillna(\"NULL\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check species names\n",
    "\n",
    "Species underscored with FIX_ need review, as do sp1, sp2, sp3, sp4, sp5, sp6, sp7, as do any mention of unknown/undefined.\n",
    "TODO:\n",
    "- check species with species name checker to make sure all is good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"ScientificName\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_species(name):\n",
    "    if name in {\"sp1\", \"sp2\"}:\n",
    "        return f\"FIX_{name}\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"ScientificName\"] = combined_df[\"ScientificName\"].apply(rename_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check MaxIterval & TimeOfMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"MaxInterval\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"TimeOfMax\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any times that do not follow the predefined format or NULL\n",
    "# TODO: now this checks that the string is 8 long, it would be good to check with a regex str\n",
    "combined_df[(combined_df[\"TimeOfMax\"].str.len() != 8) & (combined_df[\"TimeOfMax\"] != 'NULL')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare SurveyID presence in annotation vs metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surveyIDs_annotations_set = set(combined_df['DropID'].str[:16].unique())\n",
    "len(surveyIDs_annotations_set), surveyIDs_annotations_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_handler = S3Handler()\n",
    "surveys_df = s3_handler.read_df_from_s3_csv(S3_SHAREPOINT_SURVEY_CSV )\n",
    "surveyIDs_metadata_set = set(surveys_df[\"SurveyID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common = surveyIDs_annotations_set & surveyIDs_metadata_set\n",
    "only_in_annotations = surveyIDs_annotations_set - surveyIDs_metadata_set\n",
    "only_in_surveys = surveyIDs_metadata_set - surveyIDs_annotations_set\n",
    "\n",
    "\n",
    "print(f\"Reviewing files annotations and surveys, there are {len(common)} SurveyIDs in common.\" )\n",
    "print(f\"The two files have the following {len(common)} SurveyIds in common:\")\n",
    "print(sorted(list(common)))\n",
    "\n",
    "print(f\"The {len(only_in_annotations)} SurveyIDs present only in annotations are:\")\n",
    "print(sorted(list(only_in_annotations)))\n",
    "\n",
    "print(f\"The {len(only_in_surveys)} SurveyIDs present only in surveys are:\")\n",
    "print(sorted(list(only_in_surveys)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[combined_df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export combined_df to combined annotations file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create export folder in folder containing the annotations folder\n",
    "path_to_export = os.path.join(annotations_folder, \"export\")\n",
    "os.makedirs(path_to_export, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date for the annotations file\n",
    "current_date = str(datetime.date.today())\n",
    "current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_excel_file_name = f\"{current_date}_annotations_buv_doc_combined.csv\"\n",
    "export_location = os.path.join(path_to_export, export_excel_file_name)\n",
    "\n",
    "print(f\"File containing the concatenated annotations exported to: '{export_location}'\")\n",
    "combined_df.to_csv(export_location,index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where any cell starts with \"FIX\"\n",
    "new_df = combined_df[~combined_df.apply(lambda row: row.astype(str).str.startswith(\"FIX\").any(), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "export_excel_file_name = f\"{current_date}_annotations_buv_doc_combined_fix_removed.csv\"\n",
    "export_location = os.path.join(path_to_export, export_excel_file_name)\n",
    "\n",
    "print(f\"File containing the concatenated annotations without the rows to be fixed exported to: '{export_location}'\")\n",
    "new_df.to_csv(export_location,index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyfish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
