{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biigle Exploration\n",
    "\n",
    "This notebooks is part of the Spyfish Aoteraoa marine reserve reporting automation efforts. \n",
    "Biigle is one of the options considered as the annotation tool for experts.\n",
    "\n",
    "It is used to explore the biigle API, especially connecting to the data in the S3 bucket and export of the annotations.\n",
    "https://biigle.de/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "from sftk.common import BIIGLE_API_EMAIL, BIIGLE_API_TOKEN\n",
    "\n",
    "\n",
    "# Add biigle to your path (get from here: https://github.com/biigle/community-resources)\n",
    "import sys\n",
    "sys.path.append(\"/path/path/community-resources-master/biigle\")\n",
    "\n",
    "from biigle import Api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO \n",
    "- is it possible to limit the visible annotation options in the biigle frontend (for example limit to just square annotations?)\n",
    "- how to mark when a video has been reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = Api(BIIGLE_API_EMAIL, BIIGLE_API_TOKEN)\n",
    "volumes = api.get(\"volumes\")\n",
    "volumes.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOLUME_ID = 20177 # LOBSTER\n",
    "VOLUME_ID = 24940 # hiromi test\n",
    "PROJECT_ID = 3711 # spyfish aotearoa project\n",
    "\n",
    "# Your BIIGLE User Disk ID (get from UI or API)\n",
    "# s3 bucket reference (one and can find it from existing volumes, by calling get volumes on exisiting volume or from editing sorage disk in gui)\n",
    "DISK_ID = 98  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_info = api.get(f\"volumes/{VOLUME_ID}\") # hiromi test\n",
    "volume_info.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all projects that the user can access.\n",
    "projects = api.get('projects').json()\n",
    "projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example files \n",
    "# TODO get list automatically from AWS bucket\n",
    "\n",
    "files = [\n",
    "\"TON_20211026_BUV_TON_046_01.mp4_clip_1770_10.mp4\", \n",
    "\"TON_20211026_BUV_TON_046_01.mp4_clip_1780_10.mp4\", \n",
    "\"TON_20211026_BUV_TON_046_01.mp4_clip_1790_10.mp4\", \n",
    "\"TON_20211026_BUV_TON_046_01.mp4_clip_1800_10.mp4\", \n",
    "\"TON_20211026_BUV_TON_046_01.mp4_clip_1810_10.mp4\", \n",
    "\"TON_20211026_BUV_TON_046_01.mp4_clip_1820_10.mp4\", \n",
    "\"TON_20211026_BUV_TON_046_01.mp4_clip_1830_10.mp4\", \n",
    "\"TON_20211026_BUV_TON_046_01.mp4_clip_1840_10.mp4\", \n",
    "\"TON_20211026_BUV_TON_046_01.mp4_clip_1850_10.mp4\", \n",
    "\"TON_20211026_BUV_TON_046_01.mp4_clip_1860_10.mp4\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pending volume\n",
    "pending_volume_response = api.post(f\"projects/{PROJECT_ID}/pending-volumes\", json={\"media_type\":\"video\"})\n",
    "pending_volume_info = pending_volume_response.json()\n",
    "pending_volume_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_volume_id = pending_volume_info[\"id\"]\n",
    "# if the above fails: \n",
    "# find pending volume in gui by trying to make a new volume, then it tells you you can only have one pending volume, and the id is in the url\n",
    "\n",
    "# made with the DISK_ID value\n",
    "s3_url = f\"disk-{DISK_ID}://biigle_test\"\n",
    "volume_name = \"biigle_test\"\n",
    "fill_pv = api.put(f\"pending-volumes/{pending_volume_id}\", \n",
    "                  json={\"name\": volume_name , \n",
    "                        \"url\": s3_url, \n",
    "                        \"files\": files})\n",
    "fill_pv.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some extra potentially useful calls\n",
    "\n",
    "response_volume_files = api.get(f\"volumes/{VOLUME_ID}/files\")\n",
    "response_volume_files.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_project = api.get(f\"projects/{PROJECT_ID}/\")\n",
    "response_project.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type Ids given by biigle support: \n",
    "\n",
    "TODO add type ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO try this\n",
    "type_id = 8\n",
    "project_report = api.post(f\"projects/{PROJECT_ID}/reports\", json={\"type_id\": type_id})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_id = 8\n",
    "volume_annotations_report_response = api.post(f\"volumes/{VOLUME_ID}/reports\", json={\"type_id\": type_id})\n",
    "\n",
    "volume_annotations_report = volume_annotations_report_response.json()\n",
    "volume_annotations_report_id = volume_annotations_report[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "type_id = 10\n",
    "\n",
    "volume_report_response = api.post(f\"volumes/{VOLUME_ID}/reports\", json={\"type_id\": type_id})\n",
    "\n",
    "volume_report = volume_report_response.json()\n",
    "volume_report_id = volume_report[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_report_file =  api.get(f\"reports/{volume_annotations_report_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: extracted_biigle_annotations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "zip_file_path = \"biigle_annotations.zip\"\n",
    "with open(zip_file_path, \"wb\") as file:\n",
    "    file.write(annotation_report_file.content)\n",
    "\n",
    "extract_to_directory = \"extracted_biigle_annotations\"\n",
    "\n",
    "# Create the extraction directory if it doesn't exist\n",
    "os.makedirs(extract_to_directory, exist_ok=True)\n",
    "\n",
    "# TODO logging\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        # TODO overwriting probably not a problem if each video will have it's dropID\n",
    "        zip_ref.extractall(extract_to_directory)\n",
    "    print(f\"Files extracted to: {extract_to_directory}\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(\"Error: The downloaded file is not a valid zip file.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Zip file not found at {zip_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Search for the first CSV file in the extract_to_directory\n",
    "csv_files = glob.glob(os.path.join(extract_to_directory, \"*.csv\"))\n",
    "\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"No CSV files found in {extract_to_directory}\")\n",
    "\n",
    "if len(csv_files) > 1:\n",
    "    print(f\"⚠️ Multiple CSV files found. Using the first one: {csv_files[0]}\")\n",
    "\n",
    "path_to_report = csv_files[0]\n",
    "annotations_df = pd.read_csv(path_to_report)\n",
    "annotations_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df[annotations_df[\"shape_name\"] == \"Circle\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct api call example \n",
    "import requests\n",
    "\n",
    "# your request url:\n",
    "url = \"https://biigle.de/api/v1/projects\"\n",
    "# send the request to the API\n",
    "request = requests.get(url,\n",
    "auth=(BIIGLE_API_EMAIL,BIIGLE_API_TOKEN))\n",
    "request.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyfish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
