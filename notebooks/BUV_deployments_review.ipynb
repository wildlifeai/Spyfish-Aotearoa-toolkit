{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check BUV Deployment sheet help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the Spyfish Aotearoa data standardisation efforts, and is used to perform cleaning of the existing BUV Deployments csv file (obtained from the sharepoint list with the same name). \n",
    "\n",
    "The output of this notebook is:\n",
    "- lists of rows that have a suspicious behaviour\n",
    "- a csv file with cleaned SurveyIDs, SiteIDs, DropIDs, expected fileName, LinkToVideoFile and info weather these last two match to the existing value and what is the discrepancy. \n",
    "\n",
    "\n",
    "Some of this code will be repurposed for ongoing checks of the BUV Deployment data as part of the pipeline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following (sharepoint) lists are currently available\n",
    "\n",
    "- BUV Deployment\n",
    "- BUV Survey Metadata\n",
    "- BUV Survey Sites\n",
    "- Marine reserves\n",
    "- BUV Metadata Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last changed 2025.04.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run below code first: If you get the ModuleNotFoundError: No module named 'sftk' or similar error, \n",
    "## check the README.md Usage section for instructions or run the below code:\n",
    "\n",
    "import sys\n",
    "# sys.path.append('path/to/Spyfish-Aotearoa-toolkit')\n",
    "sys.path.append('/Users/kalindi/code/Spyfish-Aotearoa-toolkit')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import logging  # find logs here .sftk/logs/ - defined in the log_config\n",
    "import pandas as pd\n",
    "\n",
    "from sftk.utils import read_file_to_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"/Users/kalindi/code/Spyfish-Aotearoa-toolkit/sample_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877, 27)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buv_df = read_file_to_df(os.path.join(data_folder_path, \"BUV Deployment.csv\"))\n",
    "buv_doc_df = read_file_to_df(os.path.join(data_folder_path, \"Updating deployment info 21-03-25(query).csv\"))\n",
    "\n",
    "buv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DropID', 'SurveyID', 'SiteID', 'Latitude', 'Longitude', 'EventDate',\n",
       "       'Created By', 'TideLevel', 'Weather', 'UnderwaterVisibility',\n",
       "       'ReplicateWithinSite', 'EventTimeStart', 'EventTimeEnd',\n",
       "       'DepthDeployment', 'DepthStrata', 'NZMHCS_Abiotic', 'NZMHCS_Biotic',\n",
       "       'NotesDeployment', 'RecordedBy', 'IsBadDeployment', 'fps', 'duration',\n",
       "       'fileName', 'LinkToVideoFile', 'SamplingStart', 'SamplingEnd', 'ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buv_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resereves_df = read_file_to_df(os.path.join(data_folder_path, \"Marine Reserves.csv\"))\n",
    "resereves_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'SurveyLocationAcronym', 'MarineReserveID', 'Region',\n",
       "       'CountryCode', 'Office', 'Office Contact', 'ShortID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resereves_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df = read_file_to_df(os.path.join(data_folder_path, \"BUV Survey Metadata.csv\"))\n",
    "survey_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SurveyName', 'EncoderName', 'DateEntry', 'OfficeContact',\n",
       "       'LinkToMarineReserve', 'SurveyLocationAcronym', 'SurveyID',\n",
       "       'SurveyStartDate', 'ContractorName', 'ContractNumber',\n",
       "       'SurveyLeaderName', 'StratifiedBy', 'SiteSelectionDesign',\n",
       "       'SurveyVerbatim', 'FishMultiSpecies', 'IsLongTermMonitoring',\n",
       "       'RightsHolder', 'RecordType', 'IsMoreHabitatData', 'LinkReport01',\n",
       "       'LinkToOriginalData', 'Vessel', 'BaitSpecies', 'BaitAmount',\n",
       "       'SurveyType', 'BUVType', 'CameraModel', 'LensModel'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_df = read_file_to_df(os.path.join(data_folder_path, \"BUV Survey Sites.csv\"))\n",
    "sites_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SiteID', 'Region', 'LinkToMarineReserve', 'SiteName', 'SiteCode',\n",
       "       'SiteExposure', 'ProtectionStatus', 'ProtectionStatusDetails',\n",
       "       'IsControlSite', 'ControlToMR01', 'ControlToMR02', 'ControlToMR03',\n",
       "       'Latitude', 'Longitude', 'geodeticDatum', 'countryCode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract column sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 49\n"
     ]
    }
   ],
   "source": [
    "survey_ids = survey_df[\"SurveyID\"]\n",
    "print(len(set(survey_ids)), len(survey_ids))\n",
    "survey_ids = set(survey_ids)\n",
    "# survey_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 49\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "survey_acronyms = survey_df[\"SurveyLocationAcronym\"] \n",
    "print(len(set(survey_acronyms)), len(survey_acronyms)) # ok to differ, as there are multiple years for each acronym\n",
    "survey_acronyms = set(survey_acronyms)\n",
    "# TODO check if this is ok, these survey acronyms are added because there are acronym pairs\n",
    "survey_acronyms.update([\"CRP\", \"AKA\", \"POU\", \"BNP\"])\n",
    "print(len(survey_acronyms))\n",
    "# survey_acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 66\n"
     ]
    }
   ],
   "source": [
    "reserve_acronyms = resereves_df[\"SurveyLocationAcronym\"]\n",
    "print(len(set(reserve_acronyms)), len(reserve_acronyms))\n",
    "reserve_acronyms = set(reserve_acronyms)\n",
    "# reserve_acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1519 1539\n"
     ]
    }
   ],
   "source": [
    "site_ids = sites_df[\"SiteID\"]\n",
    "print(len(set(site_ids)), len(site_ids))\n",
    "site_ids = set(site_ids)\n",
    "# site_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check SiteID duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Check duplicate SiteIDs\n",
    "# There are 20 SiteID pairs, that are the same, quick check doesn't show massive difference\n",
    "\n",
    "duplicate_site_ids_df = sites_df[sites_df.duplicated(subset=[\"SiteID\"], keep=False)].sort_values(by=\"SiteID\")\n",
    "# duplicate_site_ids_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_site_ids_df[\"SiteID\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check all entries have respective \"parent\" in definition list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve acronyms that do not have survey equivalent\n",
    "print(len(reserve_acronyms - survey_acronyms))\n",
    "reserve_acronyms - survey_acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SurveyID acronyms that do not have equivalent in reserve acronums\n",
    "print(len(survey_acronyms - reserve_acronyms))\n",
    "survey_acronyms - reserve_acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check if survey acronyms the same as surveyIDs\n",
    "survey_df[survey_df[\"SurveyID\"].str[:3] != survey_df[\"SurveyLocationAcronym\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{nan}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SiteIDs in BUV deployment have equivalent in sites_df\n",
    "buv_sites = set(buv_df[\"SiteID\"].unique())\n",
    "buv_sites - site_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_format_match(pattern,s):\n",
    "    return bool(re.match(pattern, s))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Various Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix survey IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinations of all acronyms that can be at the beginning of a survey\n",
    "acronym_pattern = \"|\".join(survey_acronyms)\n",
    "# print(acronym_pattern)\n",
    "survey_id_pattern = fr\"^({acronym_pattern})_(\\d{{8}})_BUV$\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that all string compliant: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RTT_BUV_20250226: doesn't follow the SurveyID format\n"
     ]
    }
   ],
   "source": [
    "for survey_string in survey_ids:\n",
    "    if not is_format_match(survey_id_pattern, survey_string):\n",
    "        print(f\"{survey_string}: doesn't follow the SurveyID format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_fix_survey_ids(survey_id):\n",
    "    if survey_id == \"RTT_BUV_20250226\":\n",
    "        return \"RTT_20250226_BUV\"\n",
    "    if not is_format_match(survey_id_pattern, survey_id):\n",
    "        # logging.warning(f\"{survey_id} doesn't follow the SurveyID format\")\n",
    "        print(f\"{survey_id} doesn't follow the SurveyID format\")\n",
    "    return survey_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "buv_df[\"new_SurveyID\"] = buv_df[\"SurveyID\"].apply(confirm_fix_survey_ids)\n",
    "survey_df[\"new_SurveyID\"] = survey_df[\"SurveyID\"].apply(confirm_fix_survey_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix SiteIDs \n",
    "\n",
    "- get from siteid\n",
    "- get from filename\n",
    "- TODO: get from lat lon (Some of the SiteIDs with missing values might have some issues with Lat Lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_SiteID(row):\n",
    "    site_id = row[\"SiteID\"]\n",
    "    survey_acronym = row[\"SurveyID\"][:3]\n",
    "    site_pattern = r\"^_\\d{3}$\"\n",
    "    if pd.isna(site_id):\n",
    "        try: # filename route\n",
    "            site_acronym = row[\"fileName\"][:3]   \n",
    "            site_num = row[\"fileName\"][3:7]\n",
    "        except Exception as e:\n",
    "             return f\"FIX_{site_id}\"\n",
    "    else:\n",
    "        site_acronym = site_id[:3]\n",
    "        site_num = site_id[3:]\n",
    "    if site_acronym ==  survey_acronym or \\\n",
    "        site_acronym == \"TAW\" and survey_acronym == \"CRP\": # added options for\n",
    "         if is_format_match(site_pattern, site_num):\n",
    "              return site_acronym + site_num\n",
    "         \n",
    "    return f\"FIX_{site_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 28)\n",
      "(25, 29)\n"
     ]
    }
   ],
   "source": [
    "print(buv_df[buv_df[\"SiteID\"].isna()].shape)\n",
    "buv_df[\"new_SiteID\"] = buv_df.apply(fix_SiteID, axis=1)\n",
    "print(buv_df[buv_df[\"new_SiteID\"].astype(str).str.startswith(\"FIX\")].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "buv_df[buv_df[\"new_SiteID\"].astype(str).str.startswith(\"FIX\")]\n",
    "# WGI_20220518_BUV\tAHE_060 - are they also related?\n",
    "# RON_20250128_BUV has plus LAT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get repeated DeploymentIDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happens when the first tries are null or bad deployments, highest duplicate_count should be at the good deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(buv_df.duplicated(subset=[\"SurveyID\", \"new_SiteID\"], keep=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buv_df[\"duplicate_count\"] = buv_df.groupby([\"new_SurveyID\", \"new_SiteID\"]).cumcount() + 1\n",
    "len(buv_df[buv_df[\"duplicate_count\"].isna()]) # should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Potential issue: ANG lots of bad deployment not many redones\n",
    "buv_df[buv_df[\"SurveyID\"].str.startswith(\"ANG\")][[\"new_SurveyID\", \"new_SiteID\",\"duplicate_count\", \"IsBadDeployment\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_new_DropID(row):\n",
    "     return f'{row[\"SurveyID\"]}_{row[\"new_SiteID\"]}_{int(row[\"duplicate_count\"]):02d}'\n",
    "\n",
    "buv_df[\"new_DropID\"] = buv_df.apply(make_new_DropID, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(buv_df[buv_df.duplicated(subset=[\"new_DropID\"], keep=False)]) # should be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new fileName and LinkToVideoFile entries with new_DropID info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buv_df[\"new_fileName\"] = buv_df[\"new_DropID\"] + \".mp4\"\n",
    "buv_df[\"new_fileName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example LinkToVideoFile: SurveyID/DropID/fileName\n",
    "# buv_df[\"LinkToVideoFile\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buv_df[\"new_LinkToVideoFile\"] = buv_df[\"new_SurveyID\"]  + \"/\" + buv_df[\"new_DropID\"] + \"/\" +  buv_df[\"new_fileName\"]\n",
    "buv_df[\"new_LinkToVideoFile\"]\n",
    "\n",
    "# TODO Microsoft/mac difference in direction of slashes, does it matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_match_fileName(row):\n",
    "    if row[\"fileName\"] ==  row[\"new_fileName\"]:\n",
    "        return \"True\"\n",
    "    try: \n",
    "        # if there \n",
    "        if row[\"fileName\"][:-7] + row[\"fileName\"][-5:] == row[\"new_fileName\"]:\n",
    "            return \"digit_num\"\n",
    "    except:\n",
    "        # print(row[\"fileName\"])\n",
    "        pass\n",
    "    try: \n",
    "        # if there is a discrepancy with the duplicate number\n",
    "        if row[\"fileName\"][:-5] == row[\"new_fileName\"][:-5] and row[\"fileName\"][-5] != row[\"new_fileName\"][-5]:\n",
    "            return \"deployment_duplicate\"\n",
    "    except:\n",
    "        # print(row[\"fileName\"])\n",
    "        pass\n",
    "        \n",
    "    return \"False\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create columns with the info wather the old and new columns match/are the same\n",
    "buv_df[\"match_fileName\"] = buv_df.apply(is_match_fileName, axis=1)\n",
    "buv_df[\"match_LinkToVideoFile\"] = buv_df[\"LinkToVideoFile\"] == buv_df[\"new_LinkToVideoFile\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check more closely the situations where the duplicate num does not match.\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    display( buv_df[(buv_df[\"match_fileName\"] == \"deployment_duplicate\")][[\"fileName\", \"new_fileName\", \"match_fileName\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all fileNames that do not match (and are not NA)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "   display( buv_df[(buv_df[\"match_fileName\"] != \"True\") & (~buv_df[\"fileName\"].isna())][[\"fileName\", \"new_fileName\", \"match_fileName\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Another example of duplicate_count issue, \n",
    "# All the SLI_20240124_BUV / SLI_105 have False isBadDeployment \n",
    "# Where is 03 ?\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "   display(buv_df[buv_df[\"new_SiteID\"] == \"SLI_105\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO another example issue DropID == SLI_20240124_BUV_SLI_005_02 but there is no 01 for that year/site\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "   display(buv_df[buv_df[\"new_SiteID\"] == \"SLI_005\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DropID', 'SurveyID', 'SiteID', 'Latitude', 'Longitude', 'EventDate',\n",
       "       'Created By', 'TideLevel', 'Weather', 'UnderwaterVisibility',\n",
       "       'ReplicateWithinSite', 'EventTimeStart', 'EventTimeEnd',\n",
       "       'DepthDeployment', 'DepthStrata', 'NZMHCS_Abiotic', 'NZMHCS_Biotic',\n",
       "       'NotesDeployment', 'RecordedBy', 'IsBadDeployment', 'fps', 'duration',\n",
       "       'fileName', 'LinkToVideoFile', 'SamplingStart', 'SamplingEnd', 'ID',\n",
       "       'new_SurveyID', 'new_SiteID', 'duplicate_count', 'new_DropID',\n",
       "       'new_fileName', 'new_LinkToVideoFile', 'match_fileName',\n",
       "       'match_LinkToVideoFile'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buv_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "buv_df.to_csv(\"BUV Deployments Comparison 2025-04-08.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to export the \"new\" version of the data, assuming it's all correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DropID', 'SurveyID', 'SiteID', 'Latitude', 'Longitude', 'EventDate',\n",
       "       'Created By', 'TideLevel', 'Weather', 'UnderwaterVisibility',\n",
       "       'ReplicateWithinSite', 'EventTimeStart', 'EventTimeEnd',\n",
       "       'DepthDeployment', 'DepthStrata', 'NZMHCS_Abiotic', 'NZMHCS_Biotic',\n",
       "       'NotesDeployment', 'RecordedBy', 'IsBadDeployment', 'fps', 'duration',\n",
       "       'fileName', 'LinkToVideoFile', 'SamplingStart', 'SamplingEnd', 'ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_export = buv_df.copy()\n",
    "to_export = to_export[['new_DropID', 'new_SurveyID', 'new_SiteID', 'Latitude', 'Longitude', 'EventDate',\n",
    "       'Created By', 'TideLevel', 'Weather', 'UnderwaterVisibility',\n",
    "       'ReplicateWithinSite', 'EventTimeStart', 'EventTimeEnd',\n",
    "       'DepthDeployment', 'DepthStrata', 'NZMHCS_Abiotic', 'NZMHCS_Biotic',\n",
    "       'NotesDeployment', 'RecordedBy', 'IsBadDeployment', 'fps', 'duration',\n",
    "       'new_fileName', 'new_LinkToVideoFile', 'SamplingStart', 'SamplingEnd', 'ID']]\n",
    "to_export.rename(columns={\n",
    "    \"new_DropID\": \"DropID\",\n",
    "    'new_SurveyID': 'SurveyID', \n",
    "    'new_SiteID': 'SiteID',\n",
    "    'new_fileName': 'fileName', \n",
    "    'new_LinkToVideoFile': 'LinkToVideoFile'\n",
    "}, inplace=True)\n",
    "to_export.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_export.to_csv(\"BUV Deployments Clean 2025-04-08.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyfish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
